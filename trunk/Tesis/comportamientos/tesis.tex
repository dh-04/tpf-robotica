\section{Arquitectura de Comportamientos}

\subsection{Introducci\'on}
Como mencionamos en las secciones anteriores, el objetivo de \'este trabajo
es desarrollar un robot aut\'onomo y reactivo que recolecte basura en un entorno
estructurado pero din\'amico, debido a que la arena (lugar donde se
mueve el robot) es transitado por personas y est\'a al aire libre.

En esta secci\'on de \emph{Arquitecturas de Comportamientos} detallamos
las acciones que deber\'ia llevar a cabo el robot y c\'omo organizar las mismas
para cumplir la meta de recolectar basura y ser aut\'onomo, es decir, decidir
por s\'i mismo las acciones a realizar en cada momento y ser capaz de mantenerse
cargado para poder continuar recolectando.

En la secci\'on \ref{inv_prev} analizamos papers relacionados con este
desarrollo, desde la forma de organizar los comportamientos, la definici\'on y
composici\'on de los mismos, hasta su implementaci\'on. En la secci\'on
\ref{arq_prop} detallamos la arquitectura elegida para llevar a cabo y
organizar los comportamientos elegidos, y las ventajas y desventajas de usar la
misma. En la secci\'on \ref{comportamientos} detallamos uno por uno los
comportamientos que elegimos para que posea el robot, y sus correspondientes
implementaciones en \emph{pseudo-c\'odigo}. En la secci\'on \ref{odometry}
explicamos que es la odometr\'ia, para qu\'e sirve y qu\'e
ventajas y desventajas tiene usarla. Tambi\'en detallamos el test utilizado
para mejorar la eficiencia de la misma. En la secci\'on \ref{interfaces}
describimos c\'omo estructuramos el controlador del robot para que podamos
ir desarrollando y probando el mismo con un simulador y minimizar el trabajo
al pasarlo a el robot f\'isico. Los resultados de performance y
eficiencia del controlador desarrollado los obtuvimos de la simulaci\'on, y los
mostramos en la secci\'on \ref{results}. Finalmente, en la secci\'on
\ref{comp_conclusion} sacamos conclusiones de los resultados obtenidos y las
dificultades encontradas a lo largo del desarrollo de \'este proyecto final.

\newpage

\subsection{Investigaciones previas}
\label{inv_prev}

A continuaci\'on presentamos trabajos realizados por otros autores
relacionados en alguna forma con el nuestro. Primero damos una breve
descripci\'on del trabajo del otro autor y luego lo comparamos con
nuestro trabajo, analizando similitudes y diferencias entre ambos.

\subsubsection{Desarrollo de comportamientos no triviales en robots reales : 
Robot recolector de basura - Stefano Nolfi \cite{nolfi:evolving}}
En este paper se muestra el uso de un Khepera con el m\'odulo Gripper en una
arena delimitada por paredes para la recolecci\'on de "basura". Dicho robot se
puede ver en la figura \ref{fig:khepera}.
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.6]{comportamientos/gripperAH.png}
\caption{Robot Khepera con el m\'odulo Gripper}
\label{fig:khepera}
\end{center}
\end{figure}
La base tiene una fuente de luz asociada y el objetivo del robot es llevar
peque\~nos objetos a un lugar de dep\'osito. Se utiliza \emph{aprendizaje por
refuerzo} para asociar las velocidades angulares de las ruedas a los diferentes
tama\~nos de las "basuras". Para obtener el comportamiento deseado se hace uso
de \emph{algoritmos gen\'eticos} y \emph{redes neuronales}. Una vez obtenido el
mismo mediante simulaci\'on en Webots, se lo prob\'o en el Khepera f\'isico.
Comparando el trabajo de Stefano Nolfi con el nuestro podemos realizar las
siguientes comparaciones:
\begin{itemize}

\item{Existencia de un dep\'osito:} Ambos tienen un dep\'osito en el cual dejar
la basura recogida y una forma de identificarla: una fuente de luz usada por
Nolfi y en nuestro trabajo, al llegar al final de una determinada l\'inea de la
arena.

\item{Autonom\'ia:} Ambos son aut\'onomos en el sentido que no son manejados
por un ente externo. En cuanto a la recarga de la bater\'ia, Nolfi no explicita
si es asistida o no; en nuestro caso, el robot se encarga de ir a la base de
recarga una vez detectada la falta de energ\'ia.

\item{M\'etodo de Recolecci\'on:} En el trabajo de Nolfi se utiliza el m\'odulo
´´Gripper'' agregado al Khepera. Este m\'odulo simula un brazo con dos dedos.
De \'esta forma, la recolecci\'on se realiza junt\'andolos y la liberaci\'on 
se realiza separ\'andolos. Nuestro trabajo se basa m\'as en la actividad humana
que en el comportamiento humano para realizar la recolecci\'on, ya que podr\'ia
compararse con un recolector de basura que primero guarda lo encontrado usando
una pala en su tacho y luego lo descarga en un dep\'osito de mayor tama\~no.

\item{M\'etodo de aprendizaje:} En nuestro trabajo no utilizamos aprendizaje
por refuerzo o algoritmos evolutivos. No es el caso de Nolfi, que
utiliza ambas t\'ecnicas para evolucionar el comportamiento deseado.

\item{Robot Utilizado:} Como mencionamos anteriormente, Nolfi utiliz\'o un
Khepera en la simulaci\'on. En nuestro trabajo utilizamos un E-puck para la
simulaci\'on, una versi\'on nueva del Khepera, pero sin el m\'odulo Gripper.
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.6]{comportamientos/e-puck.png}
\caption{Robot E-puck}
\label{fig:epuck}
\end{center}
\end{figure}

\end{itemize}

\subsubsection{Arquitectura de control para un Robot Aut\'onomo M\'ovil -
Neves And Oliveira \cite{Neves97acontrol}}
Neves y Oliveira describen en su trabajo una arquitectura de control basada en
comportamientos para un robot m\'ovil en un ambiente din\'amico, utilizando
muchos aspectos de la arquitectura \emph{Subsumption}(Ver secci\'on
\ref{arq_prop}) propuesta por \emph{Brooks} y que usamos al realizar \'este
proyecto.
\\
La arquitectura propuesta en el paper, o
\emph{Control System Arquitecture}, se basa tambi\'en en la teor\'ia de 
\emph{The Society of Mind}, escrita por \emph{Minsky}, donde el sistema es
visto como una sociedad de agentes, cada uno con una competencia particular y
que colaboran entre ellos para ayudar a la sociedad a alcanzar su meta.
La arquitectura est\'a compuesta por tres niveles: un nivel reflexivo, uno
reactivo, y otro cognitivo, aumentando la complejidad al igual que el orden en
que fueron presentados.
\\
El nivel reflexivo incluye aquellos comportamientos innatos, es decir, act\'uan
directamente como est\'imulo-respuesta. El segundo nivel, el reactivo, est\'a
compuesto por agentes que responden r\'apidamente a los est\'imulos ya que
requieren poco nivel de procesamiento. Finalmente, en el nivel cognitivo, se
encuentran los agentes encargados de guiar y administrar los comportamientos
reactivos de forma tal que el robot muestre un comportamiento orientado.
\\
Aunque la arquitectura explicada es similar a la utilizada en nuestro trabajo,
no utilizamos \'esta organizaci\'on de los comportamientos en capas. Sin
embargo, podemos divisar que algunos de los comportamientos que propusimos
corresponden a la primera capa de reflexi\'on, como por ejemplo el evitamiento
de obst\'aculos y otros podr\'ian incluirse en la segunda capa de
comportamientos reactivos, como ser\'ia deambular. Finalmente en la \'ultima
capa estar\'ia el reconocimiento de objectos debido a su gran demanda de
procesamiento.

\subsubsection{Path Planning usando Algoritmos Gen\'eticos - Salvatore Candido
\cite{salvatore}}
En este paper se describe la utilizaci\'on de algor\'itmos gen\'eticos para
resolver el problema de Path Planning. \'Este consiste en armar un
plan, una secuencia de acciones de forma tal que a partir de un punto de origen
se llegue al punto de destino, siguiendo ese plan. Debido a la
componente din\'amica de nuestro trabajo, siempre tratamos de mantener los
comportamientos del robot lo m\'as reactivos posibles, por lo que armar un plan
no ser\'ia la mejor opci\'on a utilizar. Por el contrario, el uso de
algor\'itmos gen\'eticos puede ser una herramienta que se podr\'ia llegar a
usar en una futura continuaci\'on de nuestro trabajo y que no utilizamos
por el tiempo que nos hubiese demandado.

\subsubsection{Navegaci\'on predictiva de un robot aut\'onomo - Foka And
Trahanias \cite{Foka02predictiveautonomous}}
La navegaci\'on predictiva nace como una posible soluci\'on al problema de un
robot navegando en un ambiente con muchas personas y obst\'aculos, tal como lo
es el ambiente en el cual navegar\'a nuestro robot.
\\
La forma en que es implementada por los autores es mediante un \emph{POMDP}, es
decir, un proceso de decisi\'on de markov parcialmente observable. Cabe 
destacar estas dos \'ultimas palabras, ya que indican la naturaleza del
ambiente: hay incertidumbre o falta de informaci\'on acerca de ciertas
variables del entorno. En este caso, se utiliza el \emph{POMDP} para manejar
tanto la navegaci\'on del robot como el evitamiento de obst\'aculos, un punto
en que se diferencia de lo que propusimos nosotros, que es tratar el 
\emph{wandering} de forma separada del comportamiento de evitamiento de
obst\'aculos. \'Esto, en parte, se debi\'o a causa de la arquitectura utilizada
ya que desde ese punto de vista, ambos comportamientos tienen niveles de
jerarqu\'ia muy diferentes como se puede ver en la figura
\ref{fig:architecture}.

\subsubsection{Algoritmo de navegaci\'on y evitamiento de obst\'aculos en un
entorno desconocido - Clark Et. al \cite{clark}}
En este paper se presentan dos algoritmos complementarios para la navegaci\'on
en ese tipo de entornos.
\\
El primero consiste en la navegaci\'on y un mapeo del entorno que garantiza una
cobertura completa de una arena cuyas ubicaciones de la paredes no se conocen
\emph{a priori}. Consiste b\'asicamente en un seguimiento de las paredes
complementado por una variaci\'on de \emph{flood filling} para asesgurarse la
cobertura completa de la arena. El algoritmo completo se puede apreciar en la
figura \ref{fig:clark}.
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.6]{comportamientos/clarkDiagram.png}
\caption{Algoritmo propuesto por Clark Et. al}
\label{fig:clark}
\end{center}
\end{figure}
\\
Un aut\'omata con aprendizaje estoc\'astico es el algoritmo que complementa al
primero, y su objetivo es el evitamiento de obst\'aculos. Para \'esto, se
utiliza un mecanismo de recompensa/castigo de forma tal que se adapten las
probabilidades de las acciones a tomar.
\\
En relaci\'on con nuestro trabajo, hay ciertas similitudes y diferencias,
enumeradas a continuaci\'on:
\begin{itemize}
\item{}Ambos presentan un mecanismo de ``seguimiento de'', en nuestro caso lo
hacemos con l\'ineas y basuras, en el paper se utiliza con paredes. Sin embargo,
se utilizan para objetivos diferentes. Nosotros lo usamos para dirigirnos a la
base ya que tratamos de mantener el conociemiento que el robot tiene sobre el
mundo lo m\'as acotado posible, o en el caso de las basuras, para
recolectarlas. En el paper se utiliza el mecanismo de seguir las l\'ineas para
obtener un modelo del mundo, algo que puede llegar a servir mucho en ambientes
no tan din\'amicos como el nuestro, raz\'on por la cual no elegimos
implementarlo.
\item{}Tambi\'en coincidimos con la existencia de un m\'etodo para evitar
obst\'aculos. En el paper se implementa como un aut\'omata que va aprendiendo
seg\'un los premios o castigos que recibe. En nuestro caso el comportamiento
es puramente reactivo y reacciona en base a los valores de los sensores de
distancia y no tiene memoria.
\end{itemize}

\newpage
\subsection{Arquitectura propuesta}
\label{arq_prop}
Una arquitectura basada en comportamientos define la forma en que los mismos
son especificados, desde su granularidad (qu\'e tan complejo o simple es un
comportamiento), la base para su especificaci\'on, el tipo de respuesta y la
forma en que se coordinan.
\\
La arquitectura que elegimos para desarrollar nuestro trabajo es
\emph{Subsumption}, desarrollada por Rodney Brooks a mediados de 1980.
Esta arquitectura est\'a basada en comportamientos puramente reactivos,
rompiendo as\'i con el esquema que estaba de moda en la \'epoca de
\emph{sensar-planear-actuar}. Algunos de los principios propuestos que tuvimos
en cuenta durante el desarrollo de nuestro trabajo son:
\begin{itemize}
\item{}Un comportamiento complejo no es necesariamente el producto de un
complejo sistema de control,
\item{}El mundo es el mejor modelo de \'el mismo,
\item{}La simplicidad es una virtud,
\item{}Los sistemas deben ser construidos incrementalmente.
\end{itemize}
Cada comportamiento es un par est\'imulo-respuesta. Tal como mostramos en la
figura \ref{fig:behaviour}, cada est\'imulo o respuesta puede ser inhibido o
suprimida por otros comportamientos activos. Adem\'as cada comportamiento
recibe una se\~nal de reset, que lo devuelve a su estado original.
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.85]{comportamientos/behaviour.png}
\caption{Esquema de comportamiento}
\label{fig:behaviour}
\end{center}
\end{figure}
El nombre \emph{Subsumption} proviene de la forma en que los comportamientos
son coordinados entre s\'i. Hay una jerarqu\'ia donde los comportamientos de la
arquitectura tienen mayor o menor prioridad seg\'un su posici\'on. Los
comportamientos de los niveles inferiores no tienen conocimiento de los
comportamientos de las capas superiores. Gracias a \'esto, se puede plantear
un dise\~no incremental, brindando flexibilidad, adaptaci\'on y paralelismo
al desarrollo e implementaci\'on de los comportamientos.
\\
La idea a seguir es que el mundo sea el principal medio de comunicaci\'on entre
los comportamientos. \'Esto se debe a que la respuesta de un comportamiento
ante un est\'imulo resulta en un cambio en el mundo y, por lo tanto, en la
relaci\'on del robot con el mismo. De \'esta manera, el robot en su pr\'oximo
paso sensar\'a otro estado del mundo.
\\
El procedimiento b\'asico para dise\~nar y desarrollar comportamientos para
robots con esta arquitectura es sencillo:
\begin{enumerate}
\item Especificar cualitativamente la forma en que el robot responde al mundo,
es decir, el comportamiento que realizar\'a.
\item Descomponer la especificaci\'on como un conjunto de acciones disjuntas.
\item Determinar la granularidad del comportamiento, analizando en que nivel de
la jerarqu\'ia existente se encontrar\'a y cuantas acciones disjuntas es
necesario llevar a cabo para el cumplimiento de
la tarea.
\end{enumerate}

Un ejemplo de esta arquitectura se puede observar en la figura 
\ref{fig:subsumptionExample}. En la misma hay 4 comportamientos: Homing,
Pickup, Avoiding y Wandering. Las l\'ineas que entran a cada comportamiento son
los est\'imulos ante los cuales se activan y las salidas son las
se\~nales de respuesta correspondientes. La se\~nal de respuesta de la
arquitectura es la l\'inea que sale por la derecha de la caja (Arquitectura)
que contiene la relaci\'on entre los comportamientos. Puede verse como Homing
inhibe la salida de Pickup ya que su salida entra al supresor (denotado con un
c\'irculo con una S dentro) de la salida de Pickup y por lo tanto, las salidas
de los dem\'as comportamientos, ya que su prioridad es mayor al resto. En el
caso que no est\'en presentes los est\'imulos de Homing, Pickup y Avoiding,
no hay inhibici\'on en la salida de Wandering, y por lo tanto se lleva a cabo
el comportamiento de Wandering.
\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.5]{comportamientos/subsumptionExample.png}
\caption{Ejemplo de la arquitectura Subsumption}
\label{fig:subsumptionExample}
\end{center}
\end{figure}


\newpage
\input{comportamientos/comportamientos.tex}

\newpage
\subsection{Odometr\'ia}
\label{odometry}
Para saber donde se encuentra el robot en cierto momento utilizamos odometr\'ia.
\\
Esta t\'ecnica se basa en la medici\'on del encoder en cuentas realizadas por
cada motor para obtener el desplazamiento realizado por la rueda asociada.
\\
A diferencia de los m\'etodos de posicionamiento absoluto, la odometr\'ia
da una estimaci\'on del desplazamiento \emph{local} a la ubicaci\'on anterior
del robot, por lo cual \emph{un error} en una estimaci\'on \emph{se propaga}
hacia las siguientes estimaciones. 
\\
Para calcular la posici\'on $P_n$ en el instante de tiempo n y la orientaci\'on
$O_n$ en base a la posici\'on $P_{n-1}$ en el instante (n-1) y
la correspondiente orientaci\'on $O_{n-1}$, usamos las siguientes f\'ormulas:
\begin{eqnarray}
d_l = \frac{(e_l(n) - e_l(n-1)) * R_l}{EncRes} \\
d_r = \frac{(e_r(n) - e_r(n-1)) * R_r}{EncRes} \\
lc = \frac{d_r + d_l}{2} \\
P_n = P_{n-1} + (lc * \cos{O_{n-1}},lc * \sin{O_{n-1}}) \\
O_n = O_{n-1} + \frac{d_r - d_l}{dbw}
\end{eqnarray}
donde $d_l$ y $d_r$ son las distancias recorridas por las ruedas izquierda y
derecha respectivamente. Ambas son calculadas teniendo en cuenta los valores
anteriores y actuales de los encoders $e_i(n)$, el radio de la rueda $R_i$,
la resoluci\'on del encoder $EncRes$ y es la distancia entre ruedas $dbw$.
\\
Los errores que influyen en el c\'alculo de la odometr\'ia pueden ser de dos
tipos:

\begin{itemize}

\item{Sistem\'aticos:} Son aquellos que pueden ser corregidos o tenidos en
cuenta para disminuir el error.

\item{No sistem\'aticos:} Son aquellos que pueden intentarse corregir pero
\emph{no} eliminar.

\end{itemize}

Decidimos tener en cuenta dos errores sistem\'aticos para disminuir el error
en la odometr\'ia :
\begin{itemize}
\item{Incerteza sobre la distancia entre las ruedas ($dbw$)}
\item{Ruedas con radios diferentes ($R_l$ y $R_r$)}
\end{itemize}
Tuvimos en cuenta estos errores dado que son los que m\'as contribuyen al error
acumulado a lo largo del trayecto del robot.
Para corregir estas fuentes de error, utilizamos el \emph{test del camino
bidireccional describiendo un cuadrado} (UMBmark)
\footnote{http://www-personal.umich.edu/~johannb/Papers/umbmark.pdf}. Dado que
en el momento de realizar el test no ten\'iamos un robot f\'isico, decidimos
realizar el test sobre un e-puck simulado en Webots. As\'i fuimos obteniendo
los valores de correcci\'on para los di\'ametros de las ruedas $c_i$ y la
correci\'on sobre la distancia entre las ruedas $c_{dbw}$ hasta que el error
sistem\'atico m\'aximo dejara de disminuir. En la figura \ref{fig:errsist}
mostramos c\'omo disminuye el error a lo largo de las iteraciones.

\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.6]{comportamientos/errsist.eps}
%\includegraphics[scale=0.3]{comportamientos/unk.jpg}
\caption{Error Sistem\'atico M\'aximo a lo largo de las iteraciones}
\label{fig:errsist}
\end{center}
\end{figure}

En la \'ultima iteraci\'on obtuvimos los coeficientes de correcci\'on
$c_l = 0.99998703$, $c_r = 1.00001297$ y $c_{dbw} = 1.092171094$ para ruedas
con radio $R_l = R_r = 0.205$, una distancia entre ruedas de $0.052$ y una
resoluci\'on de encoder $EncRes = 159.23$.

\subsubsection{Problemas con la odometr\'ia}
\label{odometry:problems}
A LA LA LALALA

\newpage
\subsection{Interfaces con hardware y m\'odulo de reconocimiento de objetos}
\label{interfaces}
Decidimos hacer que el controlador encargado de realizar los comportamientos
sea independiente de la forma con la que se implemente el hardware y el
reconocimiento de los objetos. Para \'esto definimos
interfaces de forma tal que el controlador las mismas y tanto el hardware
como el m\'odulo de reconocimiento de objetos puedan cambiar su
implementaci\'on pero brindando siempre la informaci\'on que necesita el
controlador para poder realizar los comportamientos. Esta decisi\'on nos
posibilit\'o realizar un controlador que sea capaz de ser ejecutado tanto en
Webots, donde se hizo el desarrollo, como en la base real del robot. Cabe
aclarar que el traspaso de la simulaci\'on a la realidad no es instant\'anea,
ya que hay que calibrar los dispositivos y realizar nuevamente la odometr\'ia,
entre otras cosas, pero el trabajo demandado es mucho menor ya que una
correcci\'on en la l\'ogica de los comportamientos se puede observar tanto en
un simulador como en la realidad.

\subsubsection{Interfaz con hardware}
La interfaz con el hardware se basa en tener clases encargadas de obtener los
valores de los sensores o del accionar de los actuadores.
\\En la implementaci\'on de la interfaz que corrimos en Webots, hic\'imos
llamadas al controlador del simulador, que utiliza sensores y actuadores
simulados.
\\En la implementaci\'on que se comunica con el robot f\'isico,
las llamadas las hicimos a un servidor encargado de enviar y recibir paquetes
del protocolo descripto en la secci\'on \ref{h_protocol} a trav\'es del puerto
serial.
\\De esta forma es cuesti\'on de decidir que implementaci\'on se usa en base
a si se quiere correr en un simulador como Webots o en el robot f\'isico. Si
quisi\'eramos usar otro simulador u otro tipo de hardware, s\'olo har\'ia falta
que implementemos la interfaz que cumpla con lo establecido e indicarle a la
capa de comportamientos que la utilice para realizar su ejecuci\'on.

\subsubsection{Interfaz con m\'odulo de reconocimiento de objetos usando
Visi\'on}
Como el controlador de comportamientos es \textbf{cliente} del m\'odulo de
reconocimiento, necesita conocer en el instante de tiempo $t$, que objetos
est\'an siendo reconocidos. Para esto el m\'odulo debe tener una fuente de
informaci\'on, en nuestro caso, una c\'amara usada en Visi\'on.
\\
Desde el punto de vista anat\'omico, \'esto se puede ver como los ojos
(c\'amara), la parte del cerebro encargada de analizar el est\'imulo recibido
(im\'agenes) por los mismos (m\'odulo de reconocimiento) y la parte del cerebro
encargada de analizar los est\'imulos recibidos y realizar las acciones
(controlador de comportamientos). Si hubi\'esemos usado alg\'un tipo de
conjunto de sensores t\'actiles para reconocer objetos (mano), en vez de
visi\'on, el m\'odulo de reconocimiento de objetos bien podr\'ia analizar la
informaci\'on que ellos proveen e informar al controlador sobre su an\'alisis.
\\
Esta analog\'ia puede llevar a pensar que los sensores de distancia u otros
dispositivos que usamos en este desarrollo bien podr\'ian formar parte de otro
m\'odulo, y no se estar\'ia equivocado. La raz\'on por la cual el m\'odulo de
visi\'on est\'a separado y el resto de los sensores no, es que el procesamiento
de una secuencia de im\'agenes es muy complejo y demandante, tal como detallamos
en la secci\'on \ref{vision}.

\newpage
\subsection{Resultados obtenidos}
\label{results}
En esta secci\'on describimos los par\'ametros que utilizamos en la
simulaci\'on para obtener los resultados sobre los diferentes
comportamientos. Luego presentamos dichos resultados y sacamos
conclusiones sobre los mismos.
\\
A lo largo del proceso de desarrollo fuimos realizando diferentes
simulaciones, de las cuales observamos defectos en las implementaciones de los
comportamientos as\'i como retardos y detalles que pod\'iamos mejorar en
algunos y que fuimos corregiendo. \\
La arena utilizada en dichas simulaciones la mostramos en la figura
\ref{fig:arena_sim}. A lo largo de la misma hay ubicados 15 objetos que simulan
ser basuras, un \'area de recarga de bater\'ia y un \'area de descarga de
basura, marcadas por el cilindro naranja. Los valores de los par\'ametros
que utilizamos  los detallamos en el cuadro \ref{sim_params}. Los \'angulos
los expresamos en radianes y las distancias las expresamos en metros, as\'i
como tambi\'en los radios, correcciones y separaciones. La resoluci\'on de la
c\'amara la expresamos en pixeles, la de la grilla en unidades y los tiempos
est\'an en milisegundos.
\begin{table}[ht]
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
			\hline
			Par\'ametro & Descripci\'on del par\'ametro & Valor \\
			\hline
			$P_r(0)$ & Posici\'on Inicial del robot & (-0.295,-0.4) \\
			$O_r(0)$ & Orientaci\'on Inicial del robot & 0 \\
			$R_r$ & Radio del robot & 0.026 \\
			$dbw$ & Distancia entre ruedas & 0.052 \\
			$c_{dbw}$ & Correcci\'on de la distancia entre ruedas & 1.09217109 \\
			$R_l$ & Radio de la rueda izquierda & 0.0205 \\
			$R_r$ & Radio de la rueda derecha & 0.0205 \\
			$c_l$ & Correcci\'on del radio de la rueda izquierda & 0.99998702 \\
			$c_r$ & Correcci\'on del radio de la rueda derecha & 1.00001297 \\
			$EncRes$ & Resoluci\'on del encoder & 159.23 \\
			$Cd$ & Distancia de la c\'amara al centro del robot & 0.0355 \\
			$Ch$ \'o $C_h$ & Altura de la c\'amara & 0.038 \\
			$FOV_h$ & Field of view horizontal & 1.1 \\
			$ac$ & \'Angulo de la c\'amara & -0.5 \\
			$C_{rw}$ & Ancho de la im\'agen obtenida de la c\'amara & 640 \\
			$C_{rh}$ & Alto de la im\'agen obtenida de la c\'amara & 480 \\
			$A_w$ & Ancho del arena & 2 \\
			$A_h$ & Alto del arena & 1.2 \\
			$A_{rw}$ & Ancho de la grilla & 100 \\
			$A_{rh}$ & Alto de la grilla & 38 \\
			$Fsd$ & Dist. s.de piso del medio al centro del robot & 0.03 \\
			$Fss$ & Separaci\'on entre sensores de piso & 0.01 \\
			$Ts$ & Time Step & 32 \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Par\'ametros utilizados para las simulaciones}
	\label{sim_params}
\end{table}

\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.25]{comportamientos/arenaSim.png}
\caption{Arena que utilizamos para las simulaciones}
\label{fig:arena_sim}
\end{center}
\end{figure}

%\subsubsection{Tiempo promedio en recolectar basura}
%Calcular t min, con un escenario donde las basuras las pongo apenas sale de la
%base
%Calcular t max, con un escenario donde las basuras estan lo m\'as lejos de la
%base posible

%\subsubsection{Tiempo promedio de wandering}
%(Tiempo en que est\'a activo el wandering)/(Tiempo total de simulaci\'on)

%\subsubsection{Distribuci\'on de tiempos entre los diferentes comportamientos}
%(tiempo de comportamiento i)/(Tiempo total de simulaci\'on)

%\subsubsection{Relaci\'on (t\_cargando + t\_ir a base) / tiempo total}
%T busqueda basura/ (t a base + tiempo carga bateria + t salir base)

%\subsubsection{Porcentaje de espacio cubierto}

%\subsubsection{Tiempo cubrir toda la arena}
En la figura \ref{fig:behaviourDistribution} mostramos la distribuci\'on
de time steps en la simulaci\'on de cada comportamiento. Podemos ver que
\emph{Recargar bater\'ia} y \emph{Descargar basura} en conjunto est\'an
activos el $54\%$ de la simulaci\'on. Los comportamientos involucrados en la
recolecci\'on de basura(\emph{Enfocar basura}, \emph{Ir a basura} y
\emph{Recolectar basura}) abarcan el $10.5\%$ del tiempo total de
simulaci\'on. El $35.5\%$ restante est\'a repartido en los comportamientos
encargados de una navegaci\'on libre de obst\'aculos y situaciones peligrosas
(\emph{Wandering}, \emph{Evitar obst\'aculos} y \emph{Salir de situaciones no
deseadas}). Todos los comportamientos relacionados con la basura(desde que se
detecta hasta que se descarga) abarcan un $43\%$ del tiempo total de
simulaci\'on. Tambi\'en se puede observar que el comportamiento que mayor
tiempo est\'a activo a lo largo de la simulaci\'on es \emph{Descargar basura}
y el que menor tiempo est\'a activo es \emph{Salir de situaciones no deseadas}.

\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.3]{comportamientos/graphics/BehaviourDistributionPieUse.png}
\caption{Distribuci\'on de los tiempos de los comportamientos en la
				simulaci\'on}
\label{fig:behaviourDistribution}
\end{center}
\end{figure}

En la figura \ref{fig:behaviourEvolution} mostramos el progreso a lo largo
de la simulaci\'on de todos los comportamientos. Observamos que en el comienzo
($0 < t < 10000$) \footnote{t es el n\'umero de time step de la simulaci\'on}
la mayor\'ia de los comportamientos est\'a activo aproximadamente la misma
cantidad de time steps, salvando el caso de \emph{Descargar Basura}. En el
per\'iodo ($40000 < t < 50000$), el comportamiento \emph{Wandering} alcanza
a estar activo la misma cantidad de steps que \emph{Ir a basura}. Podemos
ver tambi\'en que la forma en que evolucionan \emph{Enfocar basura},
\emph{Ir a basura} y \emph{Recolectar basura} a lo largo de la simulaci\'on
es muy similar, salvando la cantidad de steps que est\'an activos. La
evoluci\'on de \emph{Recargar bater\'ia} es peri\'odica: inicia con
una meseta de time steps en los cuales no est\'a activo y luego tiene
una pendiente pronunciada. Diferente es el progreso de \emph{Evitamiento
de obst\'aculos} ya que sus mesetas son las menos prolongadas y sus
pendientes son poco abruptas.

\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.25]{comportamientos/graphics/AllUse.png}
\caption{Evoluci\'on de los comportamientos a lo largo de la simulaci\'on}
\label{fig:behaviourEvolution}
\end{center}
\end{figure}

\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.25]{comportamientos/graphics/CollectUse.png}
\caption{Progreso del comportamiento \emph{Recolectar Basura}}
\label{fig:collectEvolution}
\end{center}
\end{figure}

\begin{table}[htp]
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			Comportamiento & \# total de steps activo & \# veces que se activ\'o \\
			\hline
			Wandering & 64476 & 1330 \\
			Enfocar basura & 2057 & 1384 \\
			Ir a basura & 14832 & 1218 \\
			Recolectar basura & 7166 & 15 \\
			Ir a descargar basura & 76160 & 321 \\
			Ir a recargar bater\'ia & 47188 & 265 \\
			Evitar obst\'aculos & 16843 & 1507 \\
			Salir situaciones indeseadas & 0 & 0 \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Resultados sobre steps en los cuales los comportamientos est\'an
					activos}
	\label{behaviours_stats}
\end{table}

\begin{table}[htp]
	\begin{center}
		\begin{tabular}{|c|c|c|c|}
			\hline
			Comportamiento & Promedio & Desv\'io Est\'andard & \# m\'aximo \\
			\hline
			Wandering & 48.44 & 225.07 & 2212 \\
			Enfocar basura & 1.48 & 3.27 & 67 \\
			Ir a basura & 12.17 & 58.44 & 1222 \\
			Recolectar basura & 477.73 & 0.70 & 478 \\
			Ir a descargar basura & 237.25 & 840.49 & 6012 \\
			Ir a recargar bater\'ia & 178.06 & 647.39 & 3950 \\
			Evitar obst\'aculos & 11.17 & 54.72 & 1386 \\
			Salir situaciones indeseadas & 0 & 0 & 0 \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Resultados sobre steps que los comportamientos est\'an continuamente
					activos}
	\label{behaviours_stats_active}
\end{table}

\begin{table}[htp]
	\begin{center}
		\begin{tabular}{|c|c|c|c|}
			\hline
			Comportamiento & Promedio & Desv\'io Est\'andard & \# m\'aximo \\
			\hline
			Wandering & 123.4 & 754.4 & 8351 \\
			Enfocar basura & 163.7 & 1766 & 38000 \\
			Ir a basura & 175.5 & 1811 & 38040 \\
			Recolectar basura & 13850 & 9479 & 38400 \\
			Ir a descargar basura & 473.8 & 2689 & 30520 \\
			Ir a recargar bater\'ia & 682.5 & 3322 & 23270 \\
			Evitar obst\'aculos & 140.5 & 724.3 & 9485 \\
			Salir situaciones indeseadas & - & - & - \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Resultados sobre steps que los comportamientos est\'an continuamente
					inactivos}
	\label{behaviours_stats_inactive}
\end{table}

\begin{table}[htp]
	\begin{center}
		\begin{tabular}{|c||c|c|c|c|c|c|c|c||c|c|}
		\hline
    	 & W & EB & IAB & RB & DB & R & EO & SSI & M\'aximo & Ind Max \\
		\hline
		\hline
			W & 0 & 303 & 176 & 1 & 12 & 5 & 833 & 0 & 833 & 7\\
		\hline
			EB & 238 & 0 & 1036 & 2 & 1 & 0 & 107 & 0 & 1036 & 3\\
		\hline
			IAB & 229 & 967 & 0 & 12 & 2 & 1 & 7 & 0 & 967 & 2\\
		\hline
			RB & 12 & 3 & 0 & 0 & 0 & 0 & 0 & 0 & 12 & 1\\
		\hline
			DB & 14 & 0 & 0 & 0 & 0 & 2 & 305 & 0 & 305 & 7\\
		\hline
			R & 9 & 0 & 0 & 0 & 1 & 0 & 255 & 0 & 255 & 7\\
		\hline
			EO & 828 & 111 & 6 & 0 & 305 & 257 & 0 & 0 & 828 & 1\\
		\hline
			SSI & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
		\hline
		\noalign{\smallskip}
		\hline
			M\'aximo & 828 & 967 & 1036 & 12 & 305 & 257 & 833 & 0 & - & -\\
		\hline
			Ind Max & 7 & 3 & 2 & 3 & 7 & 7 & 1 & 0 & - & -\\
		\hline
		\end{tabular}
	\end{center}
	\caption{Transiciones entre estados}
	\label{transitions}
\end{table}

\begin{figure}[htp]
\begin{center}
\includegraphics[scale=0.25]{comportamientos/graphics/areaCoveredVsTimeUse.png}
\caption{\'Area visualizada y \'area no visualizada a lo largo de la
				simulaci\'on}
\label{fig:seenArea}
\end{center}
\end{figure}

%esp_cub / (e\sp_cub + esp_nocub)
\begin{table}[htp]
	\begin{center}
		\begin{tabular}{|c||c|c|}
		\hline
			$N^\circ$ muestra & (\%) & (\%) Acumulado \\
		\hline
			1 & 0.246 & 0.246 \\
		\hline
			2 & 0.258 & 0.505 \\
		\hline
			3 & 0.081 & 0.586 \\
		\hline
			4 & 0.167 & 0.754 \\
		\hline
			5 & 0.044 & 0.798 \\
		\hline
			6 & 0.011 & 0.809 \\
		\hline
			7 & 0.017 & 0.827 \\
		\hline
			8 & 0.003 & 0.830 \\
		\hline
			9 & 0.038 & 0.869 \\
		\hline
			10 & 0.130 & 1 \\
		\hline
		\end{tabular}
	\end{center}
	\caption{Porcentaje de arena cubierta}
	\label{arena:covered}
\end{table}

\newpage
\subsection{Conclusi\'on}
\label{comp_conclusion}
Conclusi\'on de comportamientos

